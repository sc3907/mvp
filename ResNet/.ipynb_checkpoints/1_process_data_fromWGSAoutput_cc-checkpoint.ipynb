{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate files for training and prediction.\n",
    "# input is WSGA selected columns\n",
    "# remeber to change prefix to HS or HIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import numpy as np\n",
    "import sys\n",
    "import Bio.SubsMat.MatrixInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = '.HIS.'\n",
    "#prefix = '.All.'\n",
    "#prefix = '.HS.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FASTA_LOC = '/data/hq2130/large_files/resources/hg19.fasta' # need to modify\n",
    "REVEL = '/data/hq2130/large_files/revel_file/revel_all_chr.txt.gz'  # REVEL loc\n",
    "f_revel= pysam.TabixFile(REVEL)\n",
    "MPC = '/data/hq2130/large_files/fordist_constraint_official_mpc_values.txt.gz'  # mpc\n",
    "f_MPC = pysam.TabixFile(MPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioPlex\n",
      "7893\n",
      "1.787753705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def matrix_score(a_0, a_1, name_matrix=\"blosum62\"):\n",
    "    \"\"\"\n",
    "    Input: a str a_0, a str a_1, a str name_matrix\n",
    "    Output: The matrix score of a_0 and a_1 in the matrix name_matrix\n",
    "    \"\"\"\n",
    "    # Biopython also included placeholder amino acids (B. J, X, Z) in its\n",
    "    # scoring matrix.\n",
    "\n",
    "    matrix = getattr(Bio.SubsMat.MatrixInfo, name_matrix)\n",
    "\n",
    "    # Since PAM250 in Biopython is not symmetric, if (a_0, a_1) does not exist,\n",
    "    # matrix_score() will check if (a_1, a_0) exists.\n",
    "\n",
    "    if (a_0, a_1) in matrix:\n",
    "        return matrix[(a_0, a_1)]\n",
    "    elif (a_1, a_0) in matrix:\n",
    "        return matrix[(a_1, a_0)]\n",
    "    else:\n",
    "        return -1\n",
    "        #raise KeyError(\"({}, {}) does not exist in matrix.\".format(a_0, a_1))\n",
    "\n",
    "# SCORE = []\n",
    "# aasets = ['G','A','V','L','I','P','S','D','E','N','Q','K','R','H','F','Y','W','M','C','B','Z','X']\n",
    "# for a0 in aasets:\n",
    "#     for a1 in aasets:\n",
    "#         print a0, a1\n",
    "#         print matrix_score(a0,a1, 'blosum62')\n",
    "#         SCORE.append(matrix_score(a0,a1, 'blosum62'))\n",
    "# print np.median(SCORE) #-1\n",
    "# print np.mean(SCORE) #~-1\n",
    "\n",
    "        \n",
    "        \n",
    "## correct GCcontent= (pos~pos+10)/5 to (pos-5~pos+5)/10 by cc on 06/29/2017 \n",
    "def add_gc_content(info):\n",
    "    chrom, pos = info['hg19_chr'], float(info['hg19_pos(1-based)'])\n",
    "    fasta_file = FASTA_LOC\n",
    "    #fasta_file = '/home/local/ARCS/hq2130/Exome_Seq/resources/hg19.fasta' # on server\n",
    "    fastafile = pysam.Fastafile(fasta_file)\n",
    "    seq = fastafile.fetch(chrom, pos - 5, pos + 5).upper()\n",
    "    gc_count = 0\n",
    "    for dna in seq:\n",
    "        if dna in {'G', 'C'}:\n",
    "            #print dna\n",
    "            gc_count += 1\n",
    "    gc_count = gc_count / 10.0\n",
    "    info['gc_content'] = gc_count\n",
    "    return info\n",
    "\n",
    "def add_s_het(info):\n",
    "    gene = info['genename']\n",
    "    # s_het\n",
    "    info['s_het'] = 0.01876\n",
    "    if gene in s_het:\n",
    "        info['s_het'] = s_het[gene]\n",
    "    # s_het log, default for log transform of 0\n",
    "    info['s_het_log'] = np.log(0.01876) \n",
    "    if gene in s_het:\n",
    "        info['s_het_log'] = np.log(s_het[gene]) # minimal value of s_het = 0.000206342\n",
    "    # info['s_hat_log'] = -10 # default for log transform of 0\n",
    "    # if gene in s_hat:\n",
    "    #     info['s_hat_log'] = np.log(s_hat[gene])\n",
    "    return info\n",
    "\n",
    "\n",
    "# SCORE = []\n",
    "# genesets = []\n",
    "# NA_genenum =0\n",
    "# with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "#     r = csv.reader(fin)\n",
    "#     for line in r: # line is a list! not a string\n",
    "#         #print line[0]\n",
    "#         genesets.append(line)\n",
    "# for a in genesets:\n",
    "#     if a[0] in s_het.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "#         SCORE.append(s_het[a[0]])\n",
    "#     else:\n",
    "#         NA_genenum += 1\n",
    "# print np.median(SCORE) #0.0187637535\n",
    "# print np.mean(SCORE) #0.0590276137112\n",
    "# print np.min(SCORE) #0.000206342\n",
    "# print NA_genenum #2121\n",
    "\n",
    "def add_exac_metric(info):\n",
    "    info['pli'] = pli.get(info['genename'], '0.0277110067492')\n",
    "    info['lofz'] = lofz.get(info['genename'], '1.98235565023')\n",
    "    info['prec'] = prec.get(info['genename'], '0.518836940302')\n",
    "    return info\n",
    "\n",
    "# SCORE = []\n",
    "# genesets = []\n",
    "# NA_genenum =0\n",
    "# with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "#     r = csv.reader(fin)\n",
    "#     for line in r: # line is a list! not a string\n",
    "#         #print line[0]\n",
    "#         genesets.append(line)\n",
    "# for a in genesets:\n",
    "#     if a[0] in pli.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "#         SCORE.append(pli[a[0]])\n",
    "#     else:\n",
    "#         NA_genenum += 1\n",
    "# print \"pli\"\n",
    "# print np.median(SCORE) #0.0277110067492\n",
    "# print np.mean(SCORE) #0.302933467654\n",
    "# print np.min(SCORE) #5.35738960908e-91\n",
    "\n",
    "# SCORE = []\n",
    "# genesets = []\n",
    "# NA_genenum =0\n",
    "# with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "#     r = csv.reader(fin)\n",
    "#     for line in r: # line is a list! not a string\n",
    "#         #print line[0]\n",
    "#         genesets.append(line)\n",
    "# for a in genesets:\n",
    "#     if a[0] in lofz.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "#         SCORE.append(lofz[a[0]])\n",
    "#     else:\n",
    "#         NA_genenum += 1\n",
    "# print \"lofz\"\n",
    "# print np.median(SCORE) #1.98235565023\n",
    "# print np.mean(SCORE) #2.19363750372\n",
    "# print np.min(SCORE) #-9.7770738652\n",
    "\n",
    "# SCORE = []\n",
    "# genesets = []\n",
    "# NA_genenum =0\n",
    "# with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "#     r = csv.reader(fin)\n",
    "#     for line in r: # line is a list! not a string\n",
    "#         #print line[0]\n",
    "#         genesets.append(line)\n",
    "# for a in genesets:\n",
    "#     if a[0] in prec.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "#         SCORE.append(prec[a[0]])\n",
    "#     else:\n",
    "#         NA_genenum += 1\n",
    "# print \"prec\"\n",
    "# print np.median(SCORE) #0.518836940302\n",
    "# print np.mean(SCORE) #0.49179236685\n",
    "# print np.min(SCORE) #6.80216500136e-31\n",
    "\n",
    "def add_target(info, target):\n",
    "    info['target'] = target_value\n",
    "    if target_value == 'NA' and 'cancer_target' in info:\n",
    "        info['target'] = info['cancer_target']  \n",
    "    elif target_value == 'NA' and 'category' in info:\n",
    "        if info['category'] == 'TP':\n",
    "            info['target'] = 1\n",
    "        elif info['category'] == 'TN':\n",
    "            info['target'] = 0 \n",
    "    return info\n",
    "\n",
    "def add_gnomad(info):\n",
    "    info['gnomad'] = 0\n",
    "    chrom, pos = info['hg19_chr'], info['hg19_pos(1-based)']\n",
    "    ref, alt = info['ref'], info['alt']\n",
    "    var_id = '_'.join([chrom, pos, ref, alt])\n",
    "    if var_id in gnomad_af:\n",
    "        info['gnomad']= gnomad_af[var_id]    \n",
    "    return info\n",
    "\n",
    "def add_secondary(info):\n",
    "    gene, aaref = info['genename'], info['aaref']\n",
    "    info['secondary_H'] = 0\n",
    "    info['secondary_C'] = 0\n",
    "    info['secondary_E'] = 0\n",
    "    if gene in secondary:\n",
    "        aapos = info['aapos'].split(';')\n",
    "        for pos in aapos:\n",
    "            pos = int(pos)\n",
    "            # AA_seq start from 0(it's a list)\n",
    "            protein_length = len(AA_seq[gene])\n",
    "            if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                if pos in secondary[gene]:\n",
    "                    if secondary[gene][pos] == 'H':\n",
    "                        info['secondary_H'] = 1\n",
    "                    elif secondary[gene][pos] == 'C':\n",
    "                        info['secondary_C'] = 1    \n",
    "                    elif secondary[gene][pos] == 'E':\n",
    "                        info['secondary_E'] = 1\n",
    "    return info\n",
    "\n",
    "SCORE = []\n",
    "genesets = []\n",
    "NA_genenum =0\n",
    "with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "    r = csv.reader(fin)\n",
    "    for line in r: # line is a list! not a string\n",
    "        #print line[0]\n",
    "        genesets.append(line)\n",
    "for a in genesets:\n",
    "    if a[0] in secondary.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "        SCORE.append(secondary[a[0]])\n",
    "    else:\n",
    "        NA_genenum += 1\n",
    "#print \"secondary\"\n",
    "#print secondary\n",
    "#print np.median(SCORE) #0.518836940302\n",
    "#print np.mean(SCORE) #0.49179236685\n",
    "#print np.min(SCORE) #6.80216500136e-31\n",
    "\n",
    "def add_BioPlex(info):\n",
    "    ''' some feather related to protein? added all pint \n",
    "        http://bioplex.hms.harvard.edu/downloadInteractions.php\n",
    "    '''\n",
    "    gene = info['genename']\n",
    "    info['BioPlex'] = 0\n",
    "    if gene in BioPlex:\n",
    "        info['BioPlex'] = BioPlex[gene]\n",
    "    return info\n",
    "\n",
    "# SCORE = []\n",
    "# genesets = []\n",
    "# NA_genenum =0\n",
    "# with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "#     r = csv.reader(fin)\n",
    "#     for line in r: # line is a list! not a string\n",
    "#         #print line[0]\n",
    "#         genesets.append(line)\n",
    "# for a in genesets:\n",
    "#     if a[0] not in BioPlex.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "# #        print a[0]\n",
    "# #        SCORE.append(BioPlex[a[0]])\n",
    "# #    else:\n",
    "#         NA_genenum += 1\n",
    "# print \"BioPlex\"\n",
    "# #print BioPlex\n",
    "# #print np.median(SCORE) #5.8844934185\n",
    "# #print np.mean(SCORE) #9.79657004979\n",
    "# #print np.min(SCORE) #0.750463933\n",
    "# print NA_genenum\n",
    "# print BioPlex['ADA']\n",
    "\n",
    "\n",
    "def add_REVEL(info, Tabix):\n",
    "    info['REVEL'] = -1\n",
    "    chrom, pos = info['hg19_chr'], info['hg19_pos(1-based)']\n",
    "    ref, alt = info['ref'], info['alt']\n",
    "    for row in Tabix.fetch(chrom, int(pos)-1, int(pos)+1):# 0-based inputin .fetch\n",
    "        row = row.split('\\t')\n",
    "        if row[3] == ref and row[4] == alt:\n",
    "            info['REVEL'] =  row[5]\n",
    "    return info  \n",
    "\n",
    "def add_MPC(info, Tabix):\n",
    "    info['MPC'] = -1\n",
    "    info['mis_badness'] = -1\n",
    "    info['obs_exp'] = -1\n",
    "    chrom, pos = info['hg19_chr'], info['hg19_pos(1-based)']\n",
    "    ref, alt = info['ref'], info['alt']\n",
    "    for row in Tabix.fetch(chrom, int(pos)-1, int(pos)+1):# 0-based inputin .fetch\n",
    "        row = row.split('\\t')\n",
    "        if row[2] == ref and row[3] == alt:\n",
    "            info['MPC'] = row[-1]\n",
    "            info['mis_badness'] = row[-3]\n",
    "            info['obs_exp'] = row[-4]\n",
    "    return info\n",
    "\n",
    "# SCORE = []\n",
    "# genesets = []\n",
    "# NA_genenum =0\n",
    "# with open ('../data/gene/genename_list.txt','rb') as fin:\n",
    "#     r = csv.reader(fin)\n",
    "#     for line in r: # line is a list! not a string\n",
    "#         #print line[0]\n",
    "#         genesets.append(line)\n",
    "# for a in genesets:\n",
    "#     if a[0] in prec.keys(): # a is a single-item list, not hashable, cannot used as dict keys\n",
    "#         SCORE.append(prec[a[0]])\n",
    "#     else:\n",
    "#         NA_genenum += 1\n",
    "# print \"prec\"\n",
    "# print np.median(SCORE) #0.518836940302\n",
    "# print np.mean(SCORE) #0.49179236685\n",
    "# print np.min(SCORE) #6.80216500136e-31\n",
    "\n",
    "\n",
    "\n",
    "def choose_HS(info):\n",
    "    include_variants = False  \n",
    "    if float(info['pli']) < 0.5 and float(info['pli']) >= 0: # HS genes\n",
    "        include_variants = True  \n",
    "    return include_variants\n",
    "\n",
    "def choose_HIS(info):\n",
    "    include_variants = False  \n",
    "    if float(info['pli']) >= 0.5: # HIS genes\n",
    "        include_variants = True  \n",
    "    return include_variants\n",
    "\n",
    "def choose_All(info):\n",
    "    include_variants = False  \n",
    "    if float(info['pli']) >= 0: # ALL genes\n",
    "        include_variants = True  \n",
    "    return include_variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, ExAC_AF=0.01, write_head=True):\n",
    "    \"\"\" function that selected colums from wgsa, add some other feathers \n",
    "        set . into 0\n",
    "    \"\"\"\n",
    "    with open(fin, 'rU') as f:\n",
    "        positive, negative = 0, 0\n",
    "        \n",
    "        r = csv.reader(f)\n",
    "        head = r.next()\n",
    "        feat_all = wgsa_feat + add_feat + extra_feat\n",
    "        feat = []\n",
    "        for f in order_feat:\n",
    "            if f in feat_all:\n",
    "                feat.append(f)\n",
    "        for f in feat_all:\n",
    "            if f not in feat:\n",
    "                feat.append(f)\n",
    "        if write_head:\n",
    "            w.writerow(feat)\n",
    "\n",
    "        for line in r:\n",
    "            info = dict(zip(head, line))\n",
    "            aaref, aaalt, aapos = info['aaref'], info['aaalt'], info['aapos']                \n",
    "            \n",
    "            var_id = '_'.join([info['hg19_chr'], info['hg19_pos(1-based)'], info['ref'], info['alt']])\n",
    "            info['var_id'] = var_id\n",
    "            if var_id in exclude_var: continue\n",
    "\n",
    "            # exclude nonsense variants and syn\n",
    "            if aaref not in {'X', '.'} and aaalt not in [\".\", 'X']: \n",
    "                # reformat wsga feat, missing value filled with 0, will -1 be better?\n",
    "                for c in wgsa_feat:\n",
    "                    if info[c] == '.':\n",
    "                        print c\n",
    "#                         if c in {'ExAC_AF'}:\n",
    "#                             info[c] = 0\n",
    "#                         else:\n",
    "#                             info[c] = -1\n",
    "#                     else:\n",
    "#                         info[c] = float(info[c])\n",
    "                # set some default value for extra_feat\n",
    "                for c in extra_feat:\n",
    "                    info[c] = info.get(c, 'NA')\n",
    "                \n",
    "                info['genename'] = info['genename']\n",
    "                info['blosum62'] = matrix_score(aaref, aaalt, 'blosum62') # function defined in previous cell\n",
    "                info['pam250'] = matrix_score(aaref, aaalt, 'pam250')\n",
    "                \n",
    "                \n",
    "               \n",
    "                \n",
    "                # update SUMO/phospho scores\n",
    "                info['phospho_score'] = 0\n",
    "                info['phospho_cutoff'] = 0\n",
    "                info['phospho_diff'] = 0\n",
    "                gene = info['genename']\n",
    "                if gene in phosphorylation:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # pos is 1 based\n",
    "                        if pos in phosphorylation[gene]:\n",
    "                            if phosphorylation[gene][pos]['AA'] == aaref:\n",
    "                                info['phospho_score'] = phosphorylation[gene][pos]['Score']\n",
    "                                info['phospho_cutoff'] = phosphorylation[gene][pos]['Cutoff']\n",
    "                                info['phospho_diff'] = phosphorylation[gene][pos]['diff']\n",
    "                                break\n",
    "                                \n",
    "                info['SUMO_score'] = 0\n",
    "                info['SUMO_cutoff'] = 0\n",
    "                info['SUMO_diff'] = 0\n",
    "                if gene in SUMO:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # pos is 1 based\n",
    "                        if pos in SUMO[gene]:\n",
    "                            if SUMO[gene][pos]['AA'] == aaref:\n",
    "                                info['SUMO_score'] = SUMO[gene][pos]['Score']\n",
    "                                info['SUMO_cutoff'] = SUMO[gene][pos]['Cutoff']\n",
    "                                info['SUMO_diff'] = SUMO[gene][pos]['diff']\n",
    "                                break  \n",
    "                                \n",
    "                # add inteface flag\n",
    "                info['interface'] = 0\n",
    "                if gene in interface:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # AA_seq start from 0\n",
    "                        protein_length = len(AA_seq[gene])\n",
    "                        if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                            if pos in interface[gene]:\n",
    "                                info['interface'] = 1\n",
    "                                \n",
    "                # add ASA score Accessible Surface Areas\n",
    "                info['ASA'] = 0\n",
    "                if gene in ASA:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # AA_seq start from 0\n",
    "                        protein_length = len(AA_seq[gene])\n",
    "                        if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                            if pos in ASA[gene]:\n",
    "                                info['ASA'] = ASA[gene][pos]\n",
    "                \n",
    "\n",
    "                                    \n",
    "                info['ubiquitination'] = 0\n",
    "                if gene in ubiquitination:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # AA_seq start from 0\n",
    "                        protein_length = len(AA_seq[gene])\n",
    "                        if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                            if pos in ubiquitination[gene]:\n",
    "                                info['ubiquitination'] = ubiquitination[gene][pos]\n",
    "                \n",
    "                # gene specific feathers\n",
    "                info['complex_CORUM'] = 0\n",
    "                if gene in complex_CORUM:\n",
    "                    info['complex_CORUM'] = 1\n",
    "                \n",
    "                info['preppi_counts'] = 0\n",
    "                if gene in preppi:\n",
    "                    info['preppi_counts'] = preppi[gene]\n",
    "                    \n",
    "                info = add_secondary(info)\n",
    "                info = add_exac_metric(info)\n",
    "                info = add_gc_content(info)\n",
    "                info = add_s_het(info)\n",
    "                info = add_BioPlex(info)\n",
    "                info = add_MPC(info, f_MPC)\n",
    "                info = add_REVEL(info, f_revel)\n",
    "                \n",
    "                info = add_target(info, target_value)\n",
    "                info = add_gnomad(info)\n",
    "               \n",
    "                # choose variants in HIS or HS\n",
    "                if prefix == '.HS.':\n",
    "                    include_variants = choose_HS(info)\n",
    "                elif prefix == '.HIS.':\n",
    "                    include_variants = choose_HIS(info)\n",
    "                elif prefix == '.All.':\n",
    "                    include_variants = choose_All(info)\n",
    "                \n",
    "                # 201707016 remove variants with 0.1% in training/testing\n",
    "                if float(info['ExAC_AF']) > ExAC_AF:\n",
    "                    include_variants = False\n",
    "                    \n",
    "                    \n",
    "                if include_variants:\n",
    "                    if info['target'] == 1:\n",
    "                        positive += 1\n",
    "                    if info['target'] == 0:\n",
    "                        negative += 1\n",
    "                    \n",
    "                    w.writerow([info[c] for c in feat])\n",
    "                    \n",
    "    print '{} pos, {} neg'.format(positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variants excluded for training\n",
    "exclude_var = set()\n",
    "with open('../data/excluded_variants_gwas.txt') as f:\n",
    "    for line in f:\n",
    "        exclude_var.add(line.strip())  \n",
    "        \n",
    "with open('../data/input_data.exclude.txt') as f:\n",
    "    for line in f:\n",
    "        exclude_var.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02524932548e-21\n"
     ]
    }
   ],
   "source": [
    "# Load protein related annotations ## these are dictionaries !!! not array\n",
    "SUMO = np.load('../data/protein/SUMO.npy').item()\n",
    "phosphorylation = np.load('../data/protein/phosphorylation.npy').item()\n",
    "AA_seq = np.load('../data/protein/AA_seq.npy').item()\n",
    "interface = np.load('../data/protein/interface.npy').item()\n",
    "ASA = np.load('../data/protein/ASA.npy').item()\n",
    "preppi = np.load('../data/protein/preppi.npy').item()\n",
    "secondary = np.load('../data/protein/secondary.npy').item()\n",
    "ubiquitination = np.load('../data/protein/ubiquitination.npy').item()\n",
    "BioPlex = np.load('../data/protein/BioPlex.npy').item()\n",
    "\n",
    "s_het = np.load('../data/gene/s_het.npy').item()\n",
    "prec = np.load('../data/gene/prec.npy').item()\n",
    "pli = np.load('../data/gene/pli.npy').item()\n",
    "\n",
    "\n",
    "print pli['NME8']\n",
    "print pli\n",
    "print 'PREC:'\n",
    "print prec\n",
    "print \"PLI\"\n",
    "print pli\n",
    "\n",
    "lofz = np.load('../data/gene/lofz.npy').item()\n",
    "\n",
    "gnomad_af = np.load('../data/training/gnomad_af.npy').item()\n",
    "\n",
    "\n",
    "complex_CORUM = set()\n",
    "with open('../data/protein/protein_complex_CORUM.txt') as f:\n",
    "    for line in f:\n",
    "        lst = line.strip().split('\\t')\n",
    "        complex_CORUM = complex_CORUM | set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in ['BioPlex' ,'REVEL', \"MPC\",'']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature order from correlation cluster\n",
    "order_feat = [u'MutationAssessor_score_rankscore', u'VEST3_rankscore', u'Polyphen2_HDIV_rankscore',\n",
    " u'Polyphen2_HVAR_rankscore', u'SIFT_converted_rankscore', u'PROVEAN_converted_rankscore',\n",
    " u'MetaSVM_rankscore',u'MetaLR_rankscore', u'FATHMM_converted_rankscore', u'M-CAP_rankscore',\n",
    " u'GenoCanyon_score_rankscore', u'LRT_converted_rankscore', u'Eigen-PC-raw_rankscore',\n",
    " u'Eigen-phred', u'Eigen-PC-phred', u'DANN_rankscore', u'CADD_phred', u'CADD_raw_rankscore',\n",
    " u'phyloP20way_mammalian_rankscore', u'GERP++_RS_rankscore', u'SiPhy_29way_logOdds_rankscore',\n",
    " u'phastCons100way_vertebrate_rankscore', u'fathmm-MKL_coding_rankscore', u'phyloP100way_vertebrate_rankscore',\n",
    " u'MutationTaster_converted_rankscore', u'phastCons20way_mammalian_rankscore', u'GM12878_fitCons_score_rankscore',\n",
    " u'HUVEC_fitCons_score_rankscore', u'integrated_fitCons_score_rankscore',u'H1-hESC_fitCons_score_rankscore', \n",
    " u'blosum62', u'pam250', u'SUMO_diff', u'SUMO_score', u'SUMO_cutoff', u'phospho_cutoff', u'phospho_score',\n",
    " u'phospho_diff', u'lofz', u'prec', u'pli',\n",
    " u's_het', u's_het_log', u'secondary_E', u'secondary_H', u'complex_CORUM', u'preppi_counts',\n",
    " u'1000Gp3_AF', u'ExAC_AF', 'gnomad', u'ASA', u'secondary_C', u'gc_content', u'interface', u'ubiquitination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add feathers from WGSA and other inputs, some of them need to be excluded in future training\n",
    "rank_score_cols = ['SIFT_converted_rankscore', 'Polyphen2_HDIV_rankscore', 'Polyphen2_HVAR_rankscore', \n",
    " 'LRT_converted_rankscore', 'MutationTaster_converted_rankscore', 'MutationAssessor_score_rankscore', \n",
    " 'FATHMM_converted_rankscore', 'PROVEAN_converted_rankscore', 'VEST3_rankscore', \n",
    " 'MetaSVM_rankscore', 'MetaLR_rankscore', 'M-CAP_rankscore', \n",
    " 'CADD_raw_rankscore', 'DANN_rankscore', 'fathmm-MKL_coding_rankscore', \n",
    " 'Eigen-PC-raw_rankscore', 'GenoCanyon_score_rankscore', 'integrated_fitCons_score_rankscore', \n",
    " 'GM12878_fitCons_score_rankscore', 'H1-hESC_fitCons_score_rankscore', \n",
    " 'HUVEC_fitCons_score_rankscore', 'GERP++_RS_rankscore', \n",
    " 'phyloP100way_vertebrate_rankscore', 'phyloP20way_mammalian_rankscore', \n",
    " 'phastCons100way_vertebrate_rankscore', 'phastCons20way_mammalian_rankscore', \n",
    " 'SiPhy_29way_logOdds_rankscore']\n",
    "\n",
    "wgsa_feat = ['1000Gp3_AF', 'ExAC_AF', 'CADD_phred', 'Eigen-phred', 'Eigen-PC-phred', 'RVIS']\n",
    "wgsa_feat = wgsa_feat + rank_score_cols\n",
    "\n",
    "add_feat =  ['blosum62', 'pam250', 'SUMO_score', 'SUMO_cutoff', 'SUMO_diff',\n",
    "             'phospho_score', 'phospho_cutoff','phospho_diff', 'interface',\n",
    "             'ASA', 'pli', 'lofz', 'complex_CORUM', 'preppi_counts',\n",
    "             'secondary_H', 'secondary_C', 'secondary_E', 'ubiquitination',\n",
    "             's_het', 'prec', 's_het_log',   'gc_content', 'gnomad', 'BioPlex',\n",
    "             'obs_exp', 'mis_badness', 'MPC', 'REVEL', \n",
    "             'target'] \n",
    "              #MPC and REVEL will be excluded cuz models.py self.excluded.features label them with x infront\n",
    "\n",
    "# feathers used for future info\n",
    "extra_feat = ['hg19_chr', 'hg19_pos(1-based)', \n",
    "              'ref', 'alt', 'category', 'source','INFO', 'disease', 'genename', 'var_id']\n",
    "\n",
    "for i in {wgsa_feat, add_feat}:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add annotation to testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5654 pos, 2704 neg\n",
      "63 pos, 17 neg\n",
      "2002 pos, 2710 neg\n",
      "0 pos, 2083 neg\n",
      "8431 pos, 3062 neg\n",
      "4718 pos, 2513 neg\n",
      "0 pos, 0 neg\n",
      "0 pos, 0 neg\n",
      "3351 pos, 1547 neg\n",
      "2964 pos, 770 neg\n"
     ]
    }
   ],
   "source": [
    "# # metaSVM and other testing\n",
    "# fins = ['../data/metaSVM/metaSVM_train.anno.rare.csv', '../data/metaSVM/metaSVM_test1.anno.rare.csv', \n",
    "#        '../data/metaSVM/metaSVM_test2.anno.rare.csv', '../data/metaSVM/metaSVM_test3.anno.rare.csv', \n",
    "#        '../data/metaSVM/metaSVM_addtest1.anno.rare.csv', '../data/metaSVM/metaSVM_addtest2.anno.rare.csv',\n",
    "#        '../data/cancer_hotspots/cancer_sel.csv',\n",
    "#        '../data/gene_test/MCAP_test.anno.rare.csv',\n",
    "#        '../data/paper_test/ClinVar.anno.rare.csv', '../data/paper_test/UniFun.anno.rare.csv']\n",
    "\n",
    "# fouts = []\n",
    "# for f in fins:\n",
    "#     fouts.append(f.split('.csv')[0] + prefix + 'reformat.csv')\n",
    "# for fin, fout in zip(fins, fouts):\n",
    "#     with open(fout, 'w') as fw:\n",
    "#         w = csv.writer(fw)\n",
    "#         target_value = 'NA'\n",
    "#         sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add annotation to de novo case and control sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pos, 177 neg\n",
      "0 pos, 331 neg\n",
      "0 pos, 360 neg\n",
      "0 pos, 364 neg\n",
      "0 pos, 298 neg\n",
      "0 pos, 538 neg\n",
      "0 pos, 569 neg\n",
      "0 pos, 591 neg\n",
      "0 pos, 475 neg\n",
      "0 pos, 869 neg\n",
      "0 pos, 929 neg\n",
      "0 pos, 955 neg\n"
     ]
    }
   ],
   "source": [
    "# # de novo control\n",
    "# prefixs = ['.HIS.', '.HS.', '.All.']\n",
    "# for prefix in prefixs:\n",
    "#     fins = ['../data/case_control/control_900.anno.rare.csv',\n",
    "#             '../data/case_control/control_1911.anno.rare.csv',\n",
    "#             '../data/case_control/ssc_yale.anno.rare.csv',\n",
    "#             '../data/case_control/control_MarkDaly.anno.rare.csv']\n",
    "\n",
    "#     fouts = [f.split('.csv')[0] + prefix + 'reformat.csv' for f in fins]\n",
    "#     for fin, fout in zip(fins, fouts):\n",
    "#         with open(fout, 'w') as fw:\n",
    "#             w = csv.writer(fw)\n",
    "#             target_value = 0\n",
    "#             sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, \n",
    "#                             ExAC_AF=1.0/10**5,\n",
    "#                             write_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2163 pos, 0 neg\n",
      "1557 pos, 0 neg\n",
      "630 pos, 0 neg\n",
      "2083 pos, 0 neg\n",
      "100 pos, 0 neg\n",
      "2615 pos, 0 neg\n",
      "1366 pos, 0 neg\n",
      "847 pos, 0 neg\n",
      "1863 pos, 0 neg\n",
      "126 pos, 0 neg\n",
      "4778 pos, 0 neg\n",
      "2923 pos, 0 neg\n",
      "1477 pos, 0 neg\n",
      "3946 pos, 0 neg\n",
      "226 pos, 0 neg\n"
     ]
    }
   ],
   "source": [
    "# # de novo case\n",
    "# prefixs = ['.HIS.', '.HS.', '.All.']\n",
    "# for prefix in prefixs:\n",
    "#     fins = ['../data/case_control/case.anno.rare.csv', \n",
    "#             '../data/case_control/DDD_new_0.2.anno.rare.csv',\n",
    "#             '../data/case_control/chd_yale.anno.rare.csv',\n",
    "#             '../data/case_control/case_MarkDaly.anno.rare.csv',\n",
    "#             '../data/case_control/CDH_mis.rare.csv']\n",
    "\n",
    "#     fouts = [f.split('.csv')[0] + prefix + 'reformat.csv' for f in fins]\n",
    "    \n",
    "#     for fin, fout in zip(fins, fouts):\n",
    "#         with open(fout, 'w') as fw:\n",
    "#             w = csv.writer(fw)\n",
    "#             target_value = 1\n",
    "#             sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, \n",
    "#                             ExAC_AF=1.0/10**5,\n",
    "#                             write_head=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process all missense and all cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # all cancer hostspot and other files\n",
    "# fins = ['/data/hq2130/large_files/cancer_all.csv']\n",
    "\n",
    "# fouts = []\n",
    "# for f in fins:\n",
    "#     fouts.append(f.split('.csv')[0] + prefix + 'reformat.GCcorrected.csv')\n",
    "# for fin, fout in zip(fins, fouts):\n",
    "#     with open(fout, 'w') as fw:\n",
    "#         w = csv.writer(fw)\n",
    "#         target_value = 'NA'\n",
    "#         sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # all cancer hostspot and other files\n",
    "\n",
    "# prefix = '.All.'\n",
    "# fins = ['/data/hq2130/large_files/rare_missense_id.anno.rare.csv']\n",
    "\n",
    "# fouts = []\n",
    "# for f in fins:\n",
    "#     fouts.append(f.split('.csv')[0] + prefix + 'reformat.csv')\n",
    "# for fin, fout in zip(fins, fouts):\n",
    "#     with open(fout, 'w') as fw:\n",
    "#         w = csv.writer(fw)\n",
    "#         target_value = 'NA'\n",
    "#         sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, \n",
    "#                         ExAC_AF=1.0/10**2,\n",
    "#                         write_head=True)\n",
    "\n",
    "# print \"done\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add annotation for different training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/training/HGMD_DM_missense_norecceive.rare.HS.csv\n",
      "13633 pos, 0 neg\n",
      "../data/training/metaSVM_train.anno.rare.HS.csv\n",
      "7800 pos, 7377 neg\n",
      "../data/training/MPC_train.rare.HS.csv\n",
      "14 pos, 0 neg\n",
      "../data/training/clinvar_pathogenic_1-4star.rare.HS.csv\n",
      "2347 pos, 0 neg\n",
      "../data/training/DiscovEHR_rare_missense_30000.HS.csv\n",
      "0 pos, 18670 neg\n",
      "../data/training/CADD_neg_train.anno.rare.HS.csv\n",
      "0 pos, 29729 neg\n"
     ]
    }
   ],
   "source": [
    "# prefix = '.HIS.'\n",
    "# prefix = '.HS.'\n",
    "\n",
    "\n",
    "# fin = '../data/training/HGMD_DM_missense_norecceive.rare.csv'\n",
    "# outname = fin.split('.csv')[0] + prefix + 'csv'\n",
    "# print outname\n",
    "\n",
    "# with open(outname, 'w') as fw:\n",
    "#     w = csv.writer(fw)\n",
    "\n",
    "#     # HGMD positive training\n",
    "#     #fin = '../data/training/HGMD_DM_missense_anno.rare.csv' \n",
    "#     #HGMD positive training ## positive\n",
    "     \n",
    "#     target_value = 1\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, \n",
    "#                     target_value, ExAC_AF=0.01,\n",
    "#                     write_head=True)\n",
    "# fw.close()\n",
    "\n",
    "# ###\n",
    "# fin = '../data/training/metaSVM_train.anno.rare.csv' \n",
    "# outname = fin.split('.csv')[0] + prefix + 'csv'\n",
    "# print outname\n",
    "\n",
    "# with open(outname, 'w') as fw:\n",
    "#     w = csv.writer(fw)\n",
    "    \n",
    "#     # metaSVM training ## uniprot positive\n",
    "    \n",
    "#     target_value = 'NA'\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "# fw.close()\n",
    "    \n",
    "# ###\n",
    "# fin = '../data/training/MPC_train.rare.csv' \n",
    "# outname = fin.split('.csv')[0] + prefix + 'csv'\n",
    "# print outname\n",
    "\n",
    "# with open(outname, 'w') as fw:\n",
    "#     w = csv.writer(fw)       \n",
    "#     # MPC train ## from Mark Daly paper 402 HIS positive\n",
    "#     target_value = 1\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)\n",
    "# fw.close()\n",
    "\n",
    "# ###\n",
    "# fin =  '../data/training/clinvar_pathogenic_1-4star.rare.csv' \n",
    "# outname = fin.split('.csv')[0] + prefix + 'csv'\n",
    "# print outname\n",
    "\n",
    "# with open(outname, 'w') as fw:\n",
    "#     w = csv.writer(fw)     \n",
    "#     # ClinVar from cc as training \n",
    "#     target_value = 1\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "# fw.close()\n",
    "\n",
    "# ###\n",
    "# fin = '../data/training/DiscovEHR_rare_missense_30000.csv' \n",
    "# outname = fin.split('.csv')[0] + prefix + 'csv'\n",
    "# print outname\n",
    "\n",
    "# with open(outname, 'w') as fw:\n",
    "#     w = csv.writer(fw)     \n",
    "#     # Discover negative data\n",
    "#     target_value = 0\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "# fw.close()\n",
    "\n",
    "\n",
    "# ###\n",
    "# fin = '../data/training/CADD_neg_train.anno.rare.csv' \n",
    "# outname = fin.split('.csv')[0] + prefix + 'csv'\n",
    "# print outname\n",
    "\n",
    "# with open(outname, 'w') as fw:\n",
    "#     w = csv.writer(fw)     \n",
    "# #CADD negative data\n",
    "# # #     \n",
    "#     target_value = 0\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "# fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decide which training sets to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input_data.HIS.csv\n",
      "['MutationAssessor_score_rankscore', 'VEST3_rankscore', 'Polyphen2_HDIV_rankscore', 'Polyphen2_HVAR_rankscore', 'SIFT_converted_rankscore', 'PROVEAN_converted_rankscore', 'MetaSVM_rankscore', 'MetaLR_rankscore', 'FATHMM_converted_rankscore', 'M-CAP_rankscore', 'GenoCanyon_score_rankscore', 'LRT_converted_rankscore', 'Eigen-PC-raw_rankscore', 'Eigen-phred', 'Eigen-PC-phred', 'DANN_rankscore', 'CADD_phred', 'CADD_raw_rankscore', 'phyloP20way_mammalian_rankscore', 'GERP++_RS_rankscore', 'SiPhy_29way_logOdds_rankscore', 'phastCons100way_vertebrate_rankscore', 'fathmm-MKL_coding_rankscore', 'phyloP100way_vertebrate_rankscore', 'MutationTaster_converted_rankscore', 'phastCons20way_mammalian_rankscore', 'GM12878_fitCons_score_rankscore', 'HUVEC_fitCons_score_rankscore', 'integrated_fitCons_score_rankscore', 'H1-hESC_fitCons_score_rankscore', 'blosum62', 'pam250', 'SUMO_diff', 'SUMO_score', 'SUMO_cutoff', 'phospho_cutoff', 'phospho_score', 'phospho_diff', 'lofz', 'prec', 'pli', 's_het', 's_het_log', 'secondary_E', 'secondary_H', 'complex_CORUM', 'preppi_counts', '1000Gp3_AF', 'ExAC_AF', 'gnomad', 'ASA', 'secondary_C', 'gc_content', 'interface', 'ubiquitination', 'RVIS', 'BioPlex', 'obs_exp', 'mis_badness', 'MPC', 'REVEL', 'target', 'hg19_chr', 'hg19_pos(1-based)', 'ref', 'alt', 'category', 'source', 'INFO', 'disease', 'genename', 'var_id']\n"
     ]
    }
   ],
   "source": [
    "prefix = '.HIS.'\n",
    "#prefix = '.HS.'\n",
    "fnames = ['../data/training/HGMD_DM_missense_norecceive.rare' + prefix + 'csv',\n",
    "         '../data/training/metaSVM_train.anno.rare' + prefix + 'csv',\n",
    "         #'../data/training/MPC_train.rare' + prefix + 'csv' , # 400 3&4 star clinvar\n",
    "         '../data/training/clinvar_pathogenic_1-4star.rare' + prefix + 'csv' ,\n",
    "         \n",
    "          '../data/training/DiscovEHR_rare_missense_30000' + prefix + 'csv' \n",
    "          #,'../data/training/CADD_neg_train.anno.rare.csv' \n",
    "         ]\n",
    "\n",
    "outname = '../data/input_data' + prefix + 'csv'\n",
    "print outname\n",
    "with open(outname, 'w') as fw:\n",
    "    w = csv.writer(fw) # create w as an object w for writing \n",
    "    flag= 0\n",
    "    for fname in fnames:\n",
    "        with open(fname,'rb') as f:\n",
    "            r = csv.reader(f) # create an object r for read\n",
    "            if flag == 0:\n",
    "                head = r.next() \n",
    "                print head\n",
    "                w.writerow(head) # write by rows\n",
    "                flag = 1\n",
    "            for line in r: # loop through r by rows\n",
    "                w.writerow(line)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
