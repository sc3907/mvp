{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_curve, auc, precision_score\n",
    "import scipy.stats\n",
    "\n",
    "import seaborn as sns\n",
    "from MutBkgd import MutationBackground\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'HIS.'\n",
    "\n",
    "folder_prefix = '0727_old45fea_+clinvP_newZhuRate' # remember to create new folder for new sets of ROC and enrichment figure\n",
    "#folder_prefix = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, errno\n",
    "\n",
    "try:\n",
    "    os.makedirs('/home/local/ARCS/hq2130/missense/'+folder_prefix+'_ROC_figure')\n",
    "    os.makedirs('/home/local/ARCS/hq2130/missense/'+folder_prefix+'_enrich_figure')\n",
    "    print \"folder created!\"\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "s_het = np.load('../data/gene/s_het.npy').item()\n",
    "prec = np.load('../data/gene/prec.npy').item()\n",
    "pli = np.load('../data/gene/pli.npy').item()\n",
    "lofz = np.load('../data/gene/lofz.npy').item()\n",
    "\n",
    "HS_gene = set(gene for gene, pli_score in pli.iteritems() if pli_score < 0.5)\n",
    "HIS_gene = set(gene for gene, pli_score in pli.iteritems() if pli_score >= 0.5)\n",
    "prec_5 = set(gene for gene, pli_score in prec.iteritems() if pli_score >0.5)\n",
    "lofz3 = set(gene for gene, score in lofz.iteritems() if score >= 3)\n",
    "\n",
    "if prefix == 'HIS.':\n",
    "    geneset = HIS_gene \n",
    "elif prefix == 'HS.':\n",
    "    geneset = HS_gene\n",
    "elif prefix == 'All.':\n",
    "    geneset = HS_gene | HIS_gene\n",
    "else:\n",
    "    geneset = geneset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_multi_confusion_matrix(df, y_true, dataset, save=False,\n",
    "                                class_names = ['damage_negative', 'damage_positive']):\n",
    "    '''take a dataframe with predictors and y_true value, output multiple confusion matrix plot\n",
    "    '''\n",
    "    \n",
    "    # 'M-CAP_rankscore', 0.4815 is 0.025 cutoff 0.642 is 0.05 cutoff \n",
    "    col_dict={'cadd15':('CADD_phred', 15), 'cadd18':('CADD_phred', 18),\n",
    "              'cadd20':('CADD_phred', 20), 'cadd22':('CADD_phred', 22),\n",
    "              'cadd24':('CADD_phred', 24), 'cadd26':('CADD_phred', 26),\n",
    "              'cadd28':('CADD_phred', 28), 'cadd30':('CADD_phred', 30),\n",
    "              'eigen_pred10':('Eigen-phred', 10), 'eigen_pred15':('Eigen-phred', 15),\n",
    "              'eigen_pc_pred10':('Eigen-PC-phred', 10),\n",
    "              'MetaSVM>0':('MetaSVM_rankscore', 0.82271),'MetaLR>0':('MetaLR_rankscore', 0.81122),\n",
    "              'M_CAP>0.025':('M-CAP_rankscore', 0.4815), 'M_CAP>0.05':('M-CAP_rankscore', 0.642),\n",
    "              'PP2-HVAR':('Polyphen2_HVAR_rankscore', 0.6280),'FATHMM':('FATHMM_converted_rankscore', 0.8235),\n",
    "              'all_missense':('cnn_prob', 0.0),'cnn_0.05':('cnn_prob', 0.05),\n",
    "              'cnn_0.1':('cnn_prob', 0.1), 'cnn_0.2':('cnn_prob', 0.2),\n",
    "              'cnn_0.3':('cnn_prob', 0.3), 'cnn_0.4':('cnn_prob', 0.4),\n",
    "              'cnn_0.5':('cnn_prob', 0.5), 'cnn_0.6':('cnn_prob', 0.6),\n",
    "              'cnn_0.7':('cnn_prob', 0.7), 'cnn_0.8':('cnn_prob', 0.8),\n",
    "              'cnn_best_0.56':('cnn_prob', 0.56),\n",
    "              'revel_0.4':('REVEL',0.4),'revel_0.5':('REVEL',0.5),\n",
    "              'revel_0.6':('REVEL',0.6),'revel_0.7':('REVEL',0.7),'revel_0.8':('REVEL',0.8),\n",
    "              'revel_0.9':('REVEL',0.9),\n",
    "              'mpc_1':('MPC',1),'mpc_1':('MPC',2)}\n",
    "    \n",
    "    y_preds, y_algos = [], []\n",
    "    for key, (col, threshold) in col_dict.items():\n",
    "        y_algos.append(key)\n",
    "        y_preds.append(convert2binary(df, col, threshold))\n",
    "\n",
    "    infos = []\n",
    "    for y_pred, y_algo in zip(y_preds, y_algos):\n",
    "        # Compute confusion matrix\n",
    "        accuracy = accuracy_score(y_true, y_pred)# y_true <=target(true label)= 1 or 0 , y_pred = 1 or 0 depends on method and threshold\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        fdr = 1 - precision_score(y_true, y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        title = '../ccfigure/' + dataset + y_algo + '.png'\n",
    "        # Plot non-normalized confusion matrix\n",
    "        figure_title = 'Confusion matrix, without normalization\\n{}\\n{}\\n accuracy: {:.2f}\\n f1: {:.2f}\\n'.format(\n",
    "            dataset, y_algo, accuracy, f1)\n",
    "        fig = plt.figure(figsize = (5,5))\n",
    "        plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                              title=figure_title)\n",
    "        \n",
    "        if save: # now default is not save!\n",
    "            infos.append([y_algo, accuracy, f1, fdr])\n",
    "            fig.savefig(title)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "    labels = ['Col', 'accuracy', 'f1', 'FDR']            \n",
    "    df = pd.DataFrame(infos,columns=labels)\n",
    "    display(df)\n",
    "\n",
    "def convert2binary(df, col, threshold):\n",
    "    '''take a dataframe, col to compare, threshold, return the binary vector\n",
    "        convert to more elegent lambda function way \n",
    "        http://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "    '''\n",
    "    values = np.array(df[col].values)\n",
    "    values = values[~np.isnan(values)] # remove NA\n",
    "    index = values >= threshold\n",
    "    values[index] = 1\n",
    "    values[~index] = 0\n",
    "    return values\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "#     print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_names = ['damage_negative', 'damage_positive'] # 0 for 'damage_negative', 1 for 'damage_positive'\n",
    "\n",
    "# validation = '../data/output/output_data_mode5.cnn.csv'# validation is 20% of DNM not used in training and testing\n",
    "# fname = validation\n",
    "# df = pd.read_csv(fname)\n",
    "# df = df[df.training==0]\n",
    "# y_true = df.pop('target')\n",
    "# dataset = 'validation(20% HGMD,DiscovEHR)'\n",
    "# #plot_multi_confusion_matrix(df, y_true, dataset, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#fnames = ['../data/metaSVM/metaSVM_test1.anno.rare.'+prefix+'reformat.cnn.csv', # teacher7's old score using wrong GC\n",
    "#          '../data/metaSVM/metaSVM_test2.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "#          '../data/metaSVM/metaSVM_addtest1.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "#          '../data/metaSVM/metaSVM_addtest2.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "#          '../data/metaSVM/metaSVM_train.anno.rare.'+prefix+'reformat.cnn.csv']\n",
    "\n",
    "# fnames = ['../data/metaSVM/metaSVM_test1.anno.rare.'+prefix+'reformat.GCcorrected.cnn.csv', # cc's brand new score using correct GC\n",
    "#           '../data/metaSVM/metaSVM_test2.anno.rare.'+prefix+'reformat.GCcorrected.cnn.csv',\n",
    "#           '../data/metaSVM/metaSVM_addtest1.anno.rare.'+prefix+'reformat.GCcorrected.cnn.csv',\n",
    "#           '../data/metaSVM/metaSVM_addtest2.anno.rare.'+prefix+'reformat.GCcorrected.cnn.csv',\n",
    "#           '../data/metaSVM/metaSVM_train.anno.rare.'+prefix+'reformat.GCcorrected.cnn.csv']\n",
    "\n",
    "# for fname in fnames:\n",
    "#     df = pd.read_csv(fname)\n",
    "#     y_true = df.pop('target')\n",
    "#     dataset = fname.split('_')[-1].split('.')[0]\n",
    "#     print dataset\n",
    "#     plot_multi_confusion_matrix(df, y_true, dataset, save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cc's new function for roc curve \n",
    "## specify font size!!!\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "# Set the font dictionaries (for plot title and axis titles)\n",
    "title_font = {'fontname':'Helvetica', 'size':'22', 'color':'black', 'weight':'normal',\n",
    "              'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname':'Helvetica', 'size':'22'}\n",
    "\n",
    "# Set the font properties (for use in legend)   \n",
    "font_path = '../../Helvetica-Regular.ttf'\n",
    "font_prop = font_manager.FontProperties(fname=font_path, size=22)\n",
    "\n",
    "'''\n",
    "ax = plt.subplot() # Defines ax variable by creating an empty plot\n",
    "\n",
    "# Set the tick labels font\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontname('Arial')\n",
    "    label.set_fontsize(20)\n",
    "'''\n",
    "\n",
    "def plot_roc(df, y_true, label):\n",
    "    \n",
    "    #### change color for curves ## tried but failed\n",
    "    #num_plots = 13\n",
    "\n",
    "    ## Have a look at the colormaps here and decide which one you'd like:\n",
    "    ## http://matplotlib.org/1.2.1/examples/pylab_examples/show_colormaps.html\n",
    "    #colormap = plt.cm.gist_ncar\n",
    "    #plt.gca().set_color_cycle([colormap(i) for i in np.linspace(0, 0.9, num_plots)])\n",
    "    \n",
    "    cpool = [ '#000000', '#bbb12d', '#1480fa', '#bd2309',\n",
    "              '#2edfea', '#ea2ec4', '#ea2e40', 'gold',#'lightgreen',#'#cdcdcd',\n",
    "              '#577a4d',  '#f59422', '#2e46c0','#219774', 'purple']#'#8086d9' ]\n",
    "    \n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    algos = ['cnn_prob', 'MetaSVM_rankscore', 'MetaLR_rankscore', 'M-CAP_rankscore', \n",
    "             'DANN_rankscore','CADD_phred', 'Eigen-phred','Polyphen2_HVAR_rankscore', \n",
    "             'MutationTaster_converted_rankscore', 'FATHMM_converted_rankscore', \n",
    "             'fathmm-MKL_coding_rankscore','REVEL', 'MPC']\n",
    "    \n",
    "    color_dict = {'cnn_prob':cpool[0], 'MetaSVM_rankscore':cpool[1], 'MetaLR_rankscore':cpool[2],\n",
    "              'M-CAP_rankscore':cpool[3], 'DANN_rankscore':cpool[4],'CADD_phred':cpool[5],\n",
    "              'Eigen-phred':cpool[6],'Polyphen2_HVAR_rankscore':cpool[7], \n",
    "              'MutationTaster_converted_rankscore':cpool[8],\n",
    "              'FATHMM_converted_rankscore':cpool[9], \n",
    "              'fathmm-MKL_coding_rankscore':cpool[10],\n",
    "              'REVEL':cpool[11], \n",
    "              'MPC':cpool[12]}\n",
    "        \n",
    "    for algo in algos:\n",
    "        index = (df[algo].notnull()) & (df[algo]!= -1) & (df[algo]!= 0) \n",
    "        y_score = df.ix[index][algo].values\n",
    "        y_true_nomissing = y_true[index]\n",
    "\n",
    "        fpr[algo], tpr[algo], _ = roc_curve(y_true_nomissing, y_score)\n",
    "        roc_auc[algo] = auc(fpr[algo], tpr[algo])\n",
    "    # jump comes from missing value\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    lw = 1.5\n",
    "    for idx, algo in enumerate(algos):\n",
    "        newalgo = algo.replace('cnn','MVP')\n",
    "        plt.plot(fpr[algo], tpr[algo], lw=lw, \n",
    "                 label='{} (area = {:.3f})'.format(newalgo.split('_')[0], roc_auc[algo]),\n",
    "                 color =color_dict[algo])\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], color='Navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate',**axis_font)\n",
    "        plt.ylabel('True Positive Rate',**axis_font)\n",
    "        \n",
    "    total = len(y_true)\n",
    "    pos = sum(y_true)\n",
    "    neg = total - pos\n",
    "    \n",
    "    plt.title('ROC of {}:\\n {} positive, {} negative'.format(label, pos, neg),**title_font)\n",
    "    plt.legend(loc=\"lower right\", fontsize = '14')\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    #plt.show()\n",
    "    #plt.savefig('../ROC_figure/ROC_'+label+'_dpi600.eps', format='eps', dpi=1200)\n",
    "    \n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters based on distance\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'dist' : pd.Series(abs(tpr-fpr), index=i), 'threshold' : pd.Series(threshold, index=i),\n",
    "                        'fpr':pd.Series(fpr, index=i), 'tpr':pd.Series(tpr, index=i)})\n",
    "    roc_t = roc.ix[roc.dist.argsort()]\n",
    "    return roc_t.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore validaiton part\n",
    "# class_names = ['damage_negative', 'damage_positive']\n",
    "# fname = validation\n",
    "# df = pd.read_csv(fname)\n",
    "# y_true = df.pop('target')\n",
    "#plot_roc(df, y_true, label = 'validation')\n",
    "#Find_Optimal_Cutoff(y_true, df['cnn_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metaSVM test\n",
    "#fnames = ['../data/metaSVM/metaSVM_test1.anno.rare.'+prefix+'reformat.cnn.csv', # teacher7's old score using wrong GC\n",
    "#          '../data/metaSVM/metaSVM_test2.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "#          '../data/metaSVM/metaSVM_addtest1.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "#          '../data/metaSVM/metaSVM_addtest2.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "#          '../data/metaSVM/metaSVM_train.anno.rare.'+prefix+'reformat.cnn.csv']\n",
    "\n",
    "fnames = ['../data/metaSVM/metaSVM_test1.anno.rare.'+prefix+'reformat.cnn.csv', # cc's brand new score using correct GC\n",
    "          '../data/metaSVM/metaSVM_test2.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "          '../data/metaSVM/metaSVM_addtest1.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "          '../data/metaSVM/metaSVM_addtest2.anno.rare.'+prefix+'reformat.cnn.csv',\n",
    "          '../data/metaSVM/metaSVM_train.anno.rare.'+prefix+'reformat.cnn.csv']\n",
    "\n",
    "labels = []\n",
    "for fname in fnames:\n",
    "    labels.append(fname.split('_')[-1].split('.')[0])\n",
    "    \n",
    "for fname, label in zip(fnames, labels):\n",
    "    df = pd.read_csv(fname)\n",
    "    y_true = df.pop('category')\n",
    "    index = y_true == 'TP'\n",
    "    y_true[index] = 1\n",
    "    y_true[~index] = 0\n",
    "    y_true = y_true.astype(int)\n",
    "    plot_roc(df, y_true, label)\n",
    "    plt.savefig('../'+folder_prefix+'_ROC_figure/ROC_'+prefix+'_'+label+'_dpi1200.eps', format='eps', dpi=1200)\n",
    "    #plt.savefig('methcomp+revel_'+fname.split('_')[-1].split('.')[0]+\".eps\", bbox_inches='tight') file not found!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test among clivar/UniFun from papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# metaSVM test\n",
    "fnames = ['../data/paper_test/ClinVar.anno.rare.' + prefix + 'reformat.cnn.csv', \n",
    "          '../data/paper_test/UniFun.anno.rare.' + prefix + 'reformat.cnn.csv']\n",
    "labels = []\n",
    "for fname in fnames:\n",
    "    labels.append(fname.split('_')[-1].split('.')[0])\n",
    "    \n",
    "for fname, label in zip(fnames, labels):\n",
    "    df = pd.read_csv(fname)\n",
    "    y_true = df.pop('category')\n",
    "    index = y_true == 'TP'\n",
    "    y_true[index] = 1\n",
    "    y_true[~index] = 0\n",
    "    y_true = y_true.astype(int)\n",
    "    plot_roc(df, y_true, label)\n",
    "    #plt.savefig('methcomp+revel_'+fname.split('_')[-1].split('.')[0]+\".png\", bbox_inches='tight') file not found!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cancer hotspot among oncogene / TS genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names = ['cancer_passengers', 'cancer_hotspot']\n",
    "fname = '../data/cancer_hotspots/cancer_sel.HIS.reformat.cnn.csv' # teacher7 old wrong GC\n",
    "#fname = '../data/cancer_hotspots/cancer_sel.HIS.reformat.GCcorrected.cnn.csv'\n",
    "cancer_HIS = pd.read_csv(fname)\n",
    "#fname = '../data/cancer_hotspots/cancer_sel.HS.reformat.cnn.csv' # teacher7 old wrong GC\n",
    "fname = '../data/cancer_hotspots/cancer_sel.HS.reformat.cnn.csv'\n",
    "cancer_HS = pd.read_csv(fname)\n",
    "cancer= pd.concat([cancer_HIS, cancer_HS], ignore_index=True)\n",
    "\n",
    "with open('../data/gene/oncogenes.txt') as f:\n",
    "    onco = set(line.strip() for line in f.readlines())\n",
    "\n",
    "with open('../data/gene/tumor_sup.txt') as f:\n",
    "    tumor_sup = set(line.strip() for line in f.readlines())\n",
    "\n",
    "cancer_genesets = [HIS_gene, tumor_sup, HIS_gene & tumor_sup, onco, HS_gene]\n",
    "cancer_genesets_label = ['HIS_gene', 'tumor_sup', 'HIS_gene & tumor_sup', 'onco', 'HS_gene']\n",
    "for idx, cancer_geneset in enumerate(cancer_genesets):\n",
    "    print len(cancer_geneset)\n",
    "    index =  cancer['genename'].isin(cancer_geneset) \n",
    "    tmp = cancer[index]\n",
    "    y_true = tmp.target\n",
    "    plot_roc(tmp, y_true, label = 'cancer ' + cancer_genesets_label[idx])\n",
    "    plt.savefig('../'+folder_prefix+'_ROC_figure/ROC_cancer'+cancer_genesets_label[idx]+'_dpi1200.eps', format='eps', dpi=1200)\n",
    "    #plt.savefig('methcomp+revel_'+'cancer'+cancer_genesets_label[idx], bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## avoid overlapping labels\n",
    "from adjustText import adjust_text\n",
    "\n",
    "## specify font size!!\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "# Set the font dictionaries (for plot title and axis titles)\n",
    "title_font = {'fontname':'Helvetica', 'size':'22', 'color':'black', 'weight':'normal',\n",
    "              'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname':'Helvetica', 'size':'22'}\n",
    "\n",
    "# Set the font properties (for use in legend)   \n",
    "font_path = '../../Helvetica-Regular.ttf'\n",
    "font_prop = font_manager.FontProperties(fname=font_path, size=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/gene/mis_rate_na0725_filtered.txt' \n",
    "#fname = '../data/gene/mis_rate_HJ0725_AF10-5_filtered.txt'\n",
    "#fname = '../data/gene/mis_rate_hongjian_one_gene0617.txt'\n",
    "\n",
    "mutation_bkgrd = MutationBackground(fname)\n",
    "\n",
    "\n",
    "def display_enrichment(case_info, control_info, case_disease, geneset, sort_key='Col'):\n",
    "    \n",
    "    print case_disease\n",
    "    df_case, case_disease, disease_size = case_info \n",
    "    df_control, control_disease, disease_size = control_info \n",
    "    \n",
    "    # recurrent variants only count once\n",
    "#     df_case = df_case.drop_duplicates(subset='var_id').reset_index()\n",
    "#     df_control = df_control.drop_duplicates(subset='var_id').reset_index()\n",
    "    \n",
    "    \n",
    "    case_size = 0.0\n",
    "    for disease in case_disease:\n",
    "        if disease in disease_size:\n",
    "            case_size += disease_size[disease]\n",
    "    control_size = 0.0\n",
    "    for disease in control_disease:\n",
    "        control_size += disease_size[disease]\n",
    "    print 'case size:{} control size:{}'.format(case_size, control_size)\n",
    "    \n",
    "    # 'M-CAP_rankscore', 0.4815 is 0.025 cutoff 0.642 is 0.05 cutoff\n",
    "    col_dict={'cadd15':('CADD_phred', 15), 'cadd18':('CADD_phred', 18),\n",
    "              'cadd20':('CADD_phred', 20), 'cadd22':('CADD_phred', 22),\n",
    "              'cadd24':('CADD_phred', 24), 'cadd26':('CADD_phred', 26),\n",
    "              'cadd28':('CADD_phred', 28), 'cadd30':('CADD_phred', 30),\n",
    "              'eigen_pred10':('Eigen-phred', 10), 'eigen_pred15':('Eigen-phred', 15),\n",
    "              'eigen_pc_pred10':('Eigen-PC-phred', 10), \n",
    "              'MetaSVM>0':('MetaSVM_rankscore', 0.82271),'MetaLR>0':('MetaLR_rankscore', 0.81122), \n",
    "              'M_CAP>0.025':('M-CAP_rankscore', 0.4815), 'M_CAP>0.05':('M-CAP_rankscore', 0.642), \n",
    "              'PP2-HVAR':('Polyphen2_HVAR_rankscore', 0.6280),'FATHMM':('FATHMM_converted_rankscore', 0.8235),\n",
    "              'all_missense':('cnn_prob', 0.0),'cnn_0.05':('cnn_prob', 0.05),\n",
    "              'cnn_0.1':('cnn_prob', 0.1), 'cnn_0.2':('cnn_prob', 0.2),\n",
    "              'cnn_0.3':('cnn_prob', 0.3), 'cnn_0.4':('cnn_prob', 0.4),\n",
    "              'cnn_0.5':('cnn_prob', 0.5), 'cnn_0.6':('cnn_prob', 0.6),\n",
    "              'cnn_0.7':('cnn_prob', 0.7), 'cnn_0.8':('cnn_prob', 0.8),\n",
    "              'cnn_best_0.56':('cnn_prob', 0.56),\n",
    "              'revel_0.4':('REVEL',0.4),'revel_0.5':('REVEL',0.5),\n",
    "              'revel_0.6':('REVEL',0.6),'revel_0.7':('REVEL',0.7),'revel_0.8':('REVEL',0.8),\n",
    "              'revel_0.9':('REVEL',0.9)}\n",
    "    \n",
    "    col_dict={'cadd15':('CADD_phred', 15), \n",
    "              'cadd20':('CADD_phred', 20), \n",
    "              'cadd25':('CADD_phred', 25), 'cadd30':('CADD_phred', 30),\n",
    "              #'eigen_pred10':('Eigen-phred', 10), 'eigen_pred15':('Eigen-phred', 15),\n",
    "              #'eigen_pc_pred10':('Eigen-PC-phred', 10), \n",
    "              'MetaSVM>0':('MetaSVM_rankscore', 0.82271),'MetaLR>0':('MetaLR_rankscore', 0.81122), \n",
    "              'M_CAP>0.025':('M-CAP_rankscore', 0.4815), 'M_CAP>0.05':('M-CAP_rankscore', 0.642), \n",
    "              'PP2-HVAR':('Polyphen2_HVAR_rankscore', 0.6280),'FATHMM':('FATHMM_converted_rankscore', 0.8235),\n",
    "              'all_missense':('cnn_prob', -1),'cnn_0.05':('cnn_prob', 0.05),\n",
    "              'cnn_0.1':('cnn_prob', 0.1), 'cnn_0.2':('cnn_prob', 0.2),\n",
    "              'cnn_0.3':('cnn_prob', 0.3), 'cnn_0.4':('cnn_prob', 0.4),\n",
    "              'cnn_0.5':('cnn_prob', 0.5), 'cnn_0.6':('cnn_prob', 0.6),\n",
    "              'cnn_0.7':('cnn_prob', 0.7), 'cnn_0.8':('cnn_prob', 0.8),'cnn_0.9':('cnn_prob', 0.9),\n",
    "              'MPC>1':('MPC', 1), 'MPC>2':('MPC', 2),\n",
    "              'revel_0.5':('REVEL',0.5),\n",
    "              'revel_0.6':('REVEL',0.6),'revel_0.7':('REVEL',0.7),'revel_0.8':('REVEL',0.8),\n",
    "              'revel_0.9':('REVEL',0.9)}\n",
    "\n",
    "    \n",
    "    infos = [] \n",
    "    for col_name, (col, threshold) in col_dict.items():\n",
    "        case_count = np.sum(convert2binary(df_case, col, threshold))\n",
    "        control_count = np.sum(convert2binary(df_control, col, threshold))\n",
    "        control_count = max(control_count, 1) # default for 0 control\n",
    "        \n",
    "        total_counts = case_count + control_count\n",
    "        \n",
    "        #adjust the baseline mutation rate difference in cases vs controls\n",
    "        #control_count = control_count*syn_ratio[case_disease[0]]\n",
    "        case_rate = float(case_count) / case_size\n",
    "        control_rate = float(control_count) / control_size\n",
    "        enrich =  case_rate / ( control_rate * syn_ratio[case_disease[0]])\n",
    "        pvalue = scipy.stats.binom_test(case_count, \n",
    "                                        total_counts,\n",
    "                                        case_size / (case_size + control_size)) ## use raw control counts here\n",
    "        #enrich = max(enrich, 1) # do not plot if enrich <1, tpr <0, risk_gene <0\n",
    "        tpr = (enrich - 1) / enrich\n",
    "        risk_gene = case_count * tpr\n",
    "        \n",
    "        \n",
    "        exp = mutation_bkgrd.expectation(geneset, col_name) * case_size \n",
    "        if exp == 0: # use control instead\n",
    "            print \"bkgrd rate = 0, use control instead\"\n",
    "            exp = case_count - risk_gene\n",
    "            \n",
    "        bk_adjust = 1 #syn_ratio[case_disease[0]] #* 1.208321\n",
    "        #exp_enr = max(case_count / exp / bk_adjust , 1) # do not plot if enrich <1, tpr <0, risk_gene <0\n",
    "        exp_enr = case_count / exp / bk_adjust \n",
    "        exp_tpr = (exp_enr - 1) / exp_enr\n",
    "        exp_risk_gene = case_count * exp_tpr\n",
    "        \n",
    "        infos.append([col_name, case_count, control_count, \n",
    "                      enrich, pvalue, risk_gene, tpr,\n",
    "                      exp, exp_enr, exp_risk_gene, exp_tpr])\n",
    "        \n",
    "    \n",
    "    labels = ['Col', 'Case', 'Control', 'enrich', 'pvalue', '# risk gene', 'true positive rate',\n",
    "              'exp', 'exp_enr', 'exp_risk_gene', 'exp_tpr']            \n",
    "    df = pd.DataFrame(infos,columns=labels)\n",
    "    df = df.sort_values(by=sort_key, ascending=True)\n",
    "    display(df)\n",
    "    df.to_csv('../'+folder_prefix+'_enrich_figure/'+prefix+case_disease[0]+'.csv', sep='\\t')\n",
    "    plot_rate_vs_riskvariants(df, case_disease[0], vs_bkg=False)\n",
    "    plot_rate_vs_riskvariants(df, case_disease[0], vs_bkg=True)\n",
    "    return df\n",
    "\n",
    "def plot_rate_vs_riskvariants(df, title,  vs_bkg):\n",
    "    \n",
    "    ## control font size for all txt in figure\n",
    "    font = {'family' : 'Helvetica',\n",
    "            'weight' : 'normal',#bold\n",
    "            'size'   : 16}\n",
    "\n",
    "    #matplotlib.rc('font', **font)\n",
    "\n",
    "    y = list(df['true positive rate'])\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    x = list(df['# risk gene'])\n",
    "    \n",
    "    if vs_bkg:\n",
    "        y = list(df['exp_tpr'])\n",
    "        x = list(df['exp_risk_gene'])\n",
    "    \n",
    "    z = list(df['Col'])\n",
    "    \n",
    "   \n",
    "    fig, ax = plt.subplots(figsize = (15,10))\n",
    "    \n",
    "    for i, point in enumerate(zip(x,y,z)):\n",
    "        if 'cnn' in point[2]:\n",
    "            color = 'red'\n",
    "        elif 'cadd' in point[2]:\n",
    "            color = 'blue'\n",
    "        elif 'all_missense' in point[2]:\n",
    "            color = 'purple'\n",
    "        elif 'revel' in point[2]:\n",
    "            color = 'green'\n",
    "        elif 'MPC' in point[2]:\n",
    "            color = 'magenta'\n",
    "        else:\n",
    "            color = 'black'\n",
    "        if float(x[i])>0 and float(y[i])>0:\n",
    "            ax.scatter(x[i], y[i], s=100, color = color)\n",
    "    \n",
    "    ax.set_ylim(0, ymax + 0.1)\n",
    "    ax.set_ylabel('Estimated Positive Predictive Value', fontsize=20,weight='normal')\n",
    "    ax.set_xlabel('Estimated # of risk variants', fontsize=20,weight='normal')\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    \n",
    "    texts = []\n",
    "    for x,y,z in zip(x,y,z):\n",
    "        if float(x)>0 and float(y)>0:\n",
    "            z=z.replace('cnn','mvp')\n",
    "            texts.append(plt.text(x,y,z.upper(),**font)) # *args\n",
    "#     adjust_text(texts, color='black', weight='bold', size=14, \n",
    "#                 only_move = 'xy', \n",
    "#                 arrowprops=dict(arrowstyle=\"-\", facecolor='black', lw=1))\n",
    "    \n",
    "    \n",
    "    case_variants, control_variants = df.ix[df['Col']=='all_missense'][['Case', 'Control']].values[0]\n",
    "    \n",
    "    if vs_bkg:\n",
    "        fname = '../'+folder_prefix+'_enrich_figure/'+prefix+title+'vsbkg.eps'\n",
    "        title = '{} Case VS Background\\n {} variants in cases'.format(title, \n",
    "                                            case_variants)\n",
    "    else:\n",
    "        fname = '../'+folder_prefix+'_enrich_figure/'+prefix+title+'vscontrol.eps'\n",
    "        title = '{} Case VS Control\\n {} variants in cases, {} variants in controls'.format(title, \n",
    "                                            case_variants, control_variants)\n",
    "    \n",
    "    ax.set_title(title, fontsize=22)\n",
    "\n",
    "    fig.savefig(fname, format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "disease_size = {'CHD':2779, 'CDH':357,'CDH_MGH':80,\n",
    "                'ASD':3953, 'EE':264, 'ID':192,\n",
    "                'DDD_new':4293, 'DDD':1133, 'SSC':1911,\n",
    "                'CHD_yale':2645, 'SSC_yale':1789,\n",
    "                'ID_DDD_EE':5620,\n",
    "                'control':2078} \n",
    "\n",
    "#fname = '../data/case_control/ssc_yale.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "#control_disease = ['SSC_yale']\n",
    "#syn_ratio = {'CHD_yale':1.0,'ASD':1.0 ,'DDD_new':1.0,'ID_DDD_EE':1.0,'CDH':1.0} \n",
    "\n",
    "fname = '../data/case_control/control_1911.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "control_disease = ['SSC']\n",
    "syn_ratio = {'CHD_yale':1.04859,'ASD':1.02691,'DDD_new':0.99904,'ID_DDD_EE':1.13627,'CDH':1.196931\n",
    "             ,'SSC':1} # vs 1911control & bg rate\n",
    "\n",
    "#fname = '../data/case_control/control_MarkDaly.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "#control_disease = ['control']\n",
    "#syn_ratio = {'CHD_yale':1.05101,'ASD':1.02928,'DDD_new':1.001342,'ID_DDD_EE':1.13889,'CDH':1.199692} # vs MDcontrol\n",
    "\n",
    "#syn_ratio = {'CHD_yale':1.0,'ASD':1.0 ,'DDD_new':1.0,'ID_DDD_EE':1.0}\n",
    "#syn_ratio = {'CHD_yale':1.0,'ASD':1.0 ,'DDD_new':1.0,'ID_DDD_EE':1.0,'CDH':1.0} #no CDH ratio\n",
    "#syn_variant_num = {'CHD_yale':701,'ASD':1026,'DDD_new':1084,'control':524} # vs MDcontrol\n",
    "\n",
    "\n",
    "df_control = pd.read_csv(fname)\n",
    "index = df_control['disease'].isin(control_disease) & df_control['genename'].isin(geneset) \n",
    "#index = index & (df_control['prec'] >=0.8)\n",
    "\n",
    "df_control = df_control[index]\n",
    "control_info = (df_control, control_disease, disease_size)\n",
    "\n",
    "\n",
    "\n",
    "# data is a little more than ANNOVAR annotatoin, do a comparison later\n",
    "#case_diseases = [['CHD'], ['CDH'], ['ASD'],['EE'], ['ID'], ['DDD'], \n",
    "#                 ['CHD', 'CDH', 'ASD','EE', 'ID', 'DDD']]\n",
    "\n",
    "case_diseases = [ ['ASD']]\n",
    "\n",
    "for case_disease in case_diseases:\n",
    "    \n",
    "\n",
    "    fname = '../data/case_control/case.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "    df_case = pd.read_csv(fname)\n",
    "    index = df_case['disease'].isin(case_disease) & df_case['genename'].isin(geneset) \n",
    "    \n",
    "    df_case = df_case[index]\n",
    "    case_info = (df_case, case_disease, disease_size)\n",
    "    df = display_enrichment(case_info, control_info, case_disease, geneset)\n",
    "    #df.to_csv('../'+folder_prefix+'_enrich_figure/'+prefix+case_disease[0]+'.csv', sep='\\t')\n",
    "\n",
    "fname = '../data/case_control/DDD_new_0.2.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['DDD_new']\n",
    "#print syn_ratio[case_disease[0]]\n",
    "\n",
    "df_case = pd.read_csv(fname)\n",
    "index =  df_case['genename'].isin(geneset) \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment(case_info, control_info, case_disease, geneset)\n",
    "#df.to_csv('../'+folder_prefix+'_enrich_figure/'+prefix+case_disease[0]+'.csv', sep='\\t')\n",
    "\n",
    "\n",
    "fname = '../data/case_control/case_MarkDaly.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['ID_DDD_EE']\n",
    "df_case = pd.read_csv(fname)\n",
    "index = df_case['genename'].isin(geneset)    \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment(case_info, control_info, case_disease, geneset)\n",
    "#df.to_csv('../'+folder_prefix+'_enrich_figure/'+prefix+case_disease[0]+'.csv', sep='\\t')\n",
    "\n",
    "\n",
    "fname = '../data/case_control/chd_yale.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['CHD_yale']\n",
    "df_case = pd.read_csv(fname)\n",
    "index =  df_case['genename'].isin(geneset) \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment(case_info, control_info, case_disease, geneset)\n",
    "#df.to_csv('../'+folder_prefix+'_enrich_figure/'+prefix+case_disease[0]+'.csv', sep='\\t')\n",
    "\n",
    "\n",
    "# fname = '../data/case_control/CDH_mis.rare.'+prefix+'reformat.cnn.csv'\n",
    "# case_disease = ['CDH']\n",
    "# df_case = pd.read_csv(fname)\n",
    "# index =  df_case['genename'].isin(geneset) \n",
    "# df_case = df_case[index]\n",
    "# case_info = (df_case, case_disease, disease_size)\n",
    "# df = display_enrichment(case_info, control_info, case_disease, geneset)\n",
    "\n",
    "# this is the comparison between controls\n",
    "fname = '../data/case_control/control_1911.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['SSC']\n",
    "df_case = pd.read_csv(fname)\n",
    "index =  df_case['genename'].isin(geneset) \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment(case_info, control_info, case_disease, geneset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# case control enrichment line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "def display_enrichment2(case_info, control_info, case_disease):\n",
    "    \n",
    "    print case_disease\n",
    "    df_case, case_disease, disease_size = case_info \n",
    "    df_control, control_disease, disease_size = control_info \n",
    "    \n",
    "    case_size = 0.0\n",
    "    for disease in case_disease:\n",
    "        if disease in disease_size:\n",
    "            case_size += disease_size[disease]\n",
    "    control_size = 0.0\n",
    "    for disease in control_disease:\n",
    "        control_size += disease_size[disease]\n",
    "    print 'case size:{} control size:{}'.format(case_size, control_size)\n",
    "    \n",
    "    cols = ['CADD_phred', 'cnn_prob', 'MPC', 'REVEL']\n",
    "    tpr, riskg, lower_riskg, upper_riskg = [], [], [], []\n",
    "    for col in cols:\n",
    "        tpr_lst, riskg_lst, lower_riskg_lst, upper_riskg_lst = get_enr_line(\n",
    "            df_case, case_size, df_control, control_size, col)\n",
    "        \n",
    "        tpr.append(tpr_lst)\n",
    "        riskg.append(riskg_lst)\n",
    "        lower_riskg.append(lower_riskg_lst)\n",
    "        upper_riskg.append(upper_riskg_lst)\n",
    "        \n",
    "    title = ''\n",
    "    plot_rate_vs_riskvariants2(cols, tpr, riskg, lower_riskg, upper_riskg, title)\n",
    "\n",
    "def get_enr_line(df_case, case_size, df_control, control_size, col):\n",
    "    \n",
    "    tpr_lst, riskg_lst, lower_riskg_lst,  upper_riskg_lst = [], [], [], []\n",
    "    \n",
    "    index = (df_case[col].notnull()) & (df_case[col]!= -1) & (df_case[col]!= 0)\n",
    "    case_scores = sorted(df_case.ix[index][col].values)\n",
    "    case_total = len(case_scores)\n",
    "    \n",
    "    index = (df_control[col].notnull()) & (df_control[col]!= -1) & (df_control[col]!= 0)\n",
    "    control_scores = sorted(df_control.ix[index][col].values)\n",
    "    control_total = len(control_scores)\n",
    "    \n",
    "    threshold = np.unique(case_scores + control_scores)\n",
    "    min_thres, max_thres = min(threshold), max(threshold)\n",
    "    threshold = np.arange(min_thres, max_thres, (max_thres - min_thres)/50)\n",
    "    \n",
    "    for thres in threshold:\n",
    "        case_count = case_total - bisect.bisect_right(case_scores, thres)\n",
    "        control_count = control_total - bisect.bisect_right(control_scores, thres)\n",
    "        \n",
    "        if control_count != 0:\n",
    "            enrich = float(case_count) / case_size / (float(control_count) / control_size)\n",
    "            if enrich > 1:\n",
    "                tpr = (enrich - 1) / enrich\n",
    "                risk_gene = case_count * tpr\n",
    "                \n",
    "                case_lower, case_upper = binomial_ci(case_count, control_count)\n",
    "                total_counts = case_count + control_count\n",
    "                n_risk_lower = case_lower - (total_counts - case_lower) * (case_size / control_size)\n",
    "                n_risk_upper = case_upper - (total_counts - case_upper) * (case_size / control_size)\n",
    "\n",
    "                tpr_lst.append(tpr)\n",
    "                riskg_lst.append(risk_gene)\n",
    "                lower_riskg_lst.append(n_risk_lower)\n",
    "                upper_riskg_lst.append(n_risk_upper)\n",
    "                \n",
    "    return tpr_lst, riskg_lst, lower_riskg_lst, upper_riskg_lst\n",
    "    \n",
    "def plot_rate_vs_riskvariants2(cols, tpr, riskg, lower_riskg, upper_riskg, title):\n",
    "    \n",
    "    colors = {'CADD_phred':'yellow', 'cnn_prob':'red', 'MPC':'blue', 'REVEL':'green'}\n",
    "    fig, ax = plt.subplots(figsize = (15,10))\n",
    "    for c, t, r, l_r, u_r, in zip(cols, tpr, riskg, lower_riskg, upper_riskg):\n",
    "        ax.plot(t, r, label=c, color=colors[c])\n",
    "        ax.plot(t, l_r, linestyle=':', color=colors[c])\n",
    "        ax.plot(t, u_r, linestyle=':', color=colors[c])\n",
    "        \n",
    "    ax.legend()\n",
    "\n",
    "def binomial_ci(case, control):\n",
    "    \"\"\"calculte the confidence interval of case counts based on CI of p, \n",
    "    used beta method(similar outcomet as R, binomial_test method does not work well for input(2, 9))\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    case : int\n",
    "        number of case counts\n",
    "    control : int\n",
    "        number of control counts\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    lower_ci : int\n",
    "    upper_ci : int\n",
    "    \"\"\"\n",
    "    total = case + control\n",
    "    lower_p, upper_p = proportion_confint(\n",
    "        case, total, alpha=0.05, method='beta')\n",
    "    lower_ci = total * lower_p\n",
    "    upper_ci = total * upper_p\n",
    "    return lower_ci, upper_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_diseases = [ ['ASD']]\n",
    "\n",
    "for case_disease in case_diseases:\n",
    "\n",
    "    fname = '../data/case_control/case.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "    df_case = pd.read_csv(fname)\n",
    "    index = df_case['disease'].isin(case_disease) & df_case['genename'].isin(geneset) \n",
    "    \n",
    "    df_case = df_case[index]\n",
    "    case_info = (df_case, case_disease, disease_size)\n",
    "    df = display_enrichment2(case_info, control_info, case_disease)\n",
    "\n",
    "\n",
    "fname = '../data/case_control/DDD_new_0.2.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['DDD_new']\n",
    "df_case = pd.read_csv(fname)\n",
    "index =  df_case['genename'].isin(geneset) \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment2(case_info, control_info, case_disease)\n",
    "\n",
    "fname = '../data/case_control/case_MarkDaly.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['ID_DDD_EE']\n",
    "df_case = pd.read_csv(fname)\n",
    "index = df_case['genename'].isin(geneset)    \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment2(case_info, control_info, case_disease)\n",
    "\n",
    "fname = '../data/case_control/chd_yale.anno.rare.'+prefix+'reformat.cnn.csv'\n",
    "case_disease = ['CHD_yale']\n",
    "df_case = pd.read_csv(fname)\n",
    "index =  df_case['genename'].isin(geneset) \n",
    "df_case = df_case[index]\n",
    "case_info = (df_case, case_disease, disease_size)\n",
    "df = display_enrichment2(case_info, control_info, case_disease)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
